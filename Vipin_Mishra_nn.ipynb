{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "JvPphJYuSZhK",
        "Way4lakC4_p0"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Build a multiclass classification model using a custom convolutional neural network in TensorFlow. "
      ],
      "metadata": {
        "id": "0I2Fh2MoXAwQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDriIbfa5lwD"
      },
      "source": [
        "##Problem statement:\n",
        "To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfcpIXQZN2Rh"
      },
      "source": [
        "### Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC8xCQuELWms"
      },
      "source": [
        "import pathlib\n",
        "import os, shutil\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import glob\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mounting the google drive"
      ],
      "metadata": {
        "id": "229YYF9hc59Y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYpVPmT5z7AP"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpUsRQwOOL72"
      },
      "source": [
        "## Data Set details\n",
        "The dataset consists of 2357 images of malignant and benign oncological diseases, which were formed from the International Skin Imaging Collaboration (ISIC). All images were sorted according to the classification taken with ISIC, and all subsets were divided into the same number of images, with the exception of melanomas and moles, whose images are slightly dominant."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The data set contains the following diseases:\n",
        "\n",
        "- Actinic keratosis\n",
        "- Basal cell carcinoma\n",
        "- Dermatofibroma\n",
        "- Melanoma\n",
        "- Nevus\n",
        "- Pigmented benign keratosis\n",
        "- Seborrheic keratosis\n",
        "- Squamous cell carcinoma\n",
        "- Vascular lesion"
      ],
      "metadata": {
        "id": "KufwIhDKXmWd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D57L-ovIKtI4"
      },
      "source": [
        "# Defining the path for train and test images\n",
        "data_dir_train = pathlib.Path(\"/content/gdrive/MyDrive/cnn-upgrad/Train\")\n",
        "data_dir_test = pathlib.Path('/content/gdrive/MyDrive/cnn-upgrad/Test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqksN1w5Fu-N"
      },
      "source": [
        "# Counting train and test images\n",
        "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
        "print(image_count_train)\n",
        "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
        "print(image_count_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDBKZG3jPcMc"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "Define some parameters for the loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLfcXcZ9LjGv"
      },
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load using keras.preprocessing"
      ],
      "metadata": {
        "id": "QWNLm0SuYQXc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5f5y43GPog1"
      },
      "source": [
        "Use 80% of the images for training, and 20% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1BWmDzr7w-5"
      },
      "source": [
        "### Train Dataset\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir_train,\n",
        "    seed=123,\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_width,img_height),\n",
        "    validation_split=0.2,\n",
        "    subset='training'   \n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYch6-SR-i2g"
      },
      "source": [
        "### Validation Dataset\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir_train,\n",
        "    seed=123,\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_width,img_height),\n",
        "    validation_split=0.2,\n",
        "    subset='validation'   \n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk0RV7G7-nad"
      },
      "source": [
        "# Listing all the classes of skin cancer and use list to store these classes. \n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbsm5oYiQH_b"
      },
      "source": [
        "## Visualize the data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating below code to visualize one instance of all the nine classes present in the dataset"
      ],
      "metadata": {
        "id": "fdZvXa_3Y4l6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "for i in range(len(class_names)):\n",
        "    filtered_ds = train_ds.filter(lambda image, label: tf.math.equal(label[0], i))\n",
        "    for image, label in filtered_ds.take(1):\n",
        "        ax = plt.subplot(3, 3, i+1)\n",
        "        plt.imshow(image[0].numpy().astype('uint8'))\n",
        "        plt.title(class_names[label[0]])\n",
        "        plt.axis('off')"
      ],
      "metadata": {
        "id": "hiLF1xxJzrLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cAZPYaeQjQy"
      },
      "source": [
        "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzVXBHiyQ7_I"
      },
      "source": [
        "`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n",
        "\n",
        "`Dataset.prefetch()` overlaps data preprocessing and model execution while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wZlKRBEGNtU"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JEAF6-sRyz8"
      },
      "source": [
        "## Creating first model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ync9xoW7GZgn"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(len(class_names)))\n",
        "model.add(Activation('softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDKzJmHwSCtt"
      },
      "source": [
        "### Compile the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB8wKtiPGe1j"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZGWN4MZGhtJ"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljD_83rwSl5O"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkfw2rJXGlYC"
      },
      "source": [
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3679V8OShSE"
      },
      "source": [
        "### Visualizing training results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1xkgk5nGubz"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvPphJYuSZhK"
      },
      "source": [
        "## Observations\n",
        "\n",
        "The accuracy of the model for the Training data set is at 95%. But the Validation accuracy is not in par with the training accuracy. It is only at 50%. The validation loss as observed is very high. This could also be indicative of some Overfit in the model. We could add some Dropout layers to improve the accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhKDHlUdTuSX"
      },
      "source": [
        "## Creating the second model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3V4l-O9G3dM"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,kernel_regularizer=l2(0.5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(len(class_names)))\n",
        "model.add(Activation('softmax'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfUWFp96UIAN"
      },
      "source": [
        "### Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-7yTm8IG8zR"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC-D_RWOURp6"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcPfkUASHBf9"
      },
      "source": [
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhNOKtSyUYzC"
      },
      "source": [
        "### Visualizing the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjN_F4QxHIsh"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-AUR_b7UcaK"
      },
      "source": [
        "## Observations\n",
        "\n",
        "The model accuracy for Train data set has dropped to nearly 65%. The accuracy for the Validation set is at 55%. This is a much better model compared to the previous model as there seems to be No Overfit with the training accuracy 65% and validation accuracy at 55%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TdDi4u-VTkW"
      },
      "source": [
        "#### Distribution of classes in the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAhwYgtTQRzq"
      },
      "source": [
        "path_list = [x for x in glob.glob(os.path.join(data_dir_train, '*', '*.jpg'))]\n",
        "lesion_list=[ os.path.basename(os.path.dirname(x)) for x in glob.glob(os.path.join(data_dir_train, '*', '*.jpg')) ]\n",
        "dataframe_dict = dict(zip(path_list, lesion_list))\n",
        "original_df = pd.DataFrame(list(dataframe_dict.items()),columns = ['Path','Label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking for Class Imbalance using bar plot"
      ],
      "metadata": {
        "id": "cHjxpVSeeY_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_df['Label'].value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "id": "v3noSbIuddWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4csQL1dvO0b2"
      },
      "source": [
        "## Observations\n",
        "\n",
        "There is a significant Class Imbalance observed. The class with the least number of samples is Seborrheic Keratosis. The class that dominates the data in terms of proportionate number of samples is Pigmented Benign Keratosis.\n",
        "\n",
        " - Actinic Keratosos and Seborrheic keratosis has the least number of samples\n",
        " - Pigmented benign keratosis dominates the data of count more than 100 in training\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb-stKyHPf8v"
      },
      "source": [
        "##  Rectify the class imbalance using 'Augmentor'\n",
        "\n",
        "Augmentor helps to add more samples across all classes so that none of the classes have very few samples.\n",
        "\n",
        "ref: (https://augmentor.readthedocs.io/en/master/) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItAg4rU-SzJh"
      },
      "source": [
        "!pip install Augmentor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZKzTe3zWL4O"
      },
      "source": [
        "To use `Augmentor`, the following general procedure is followed:\n",
        "\n",
        "1. Instantiate a `Pipeline` object pointing to a directory containing your initial image data set.<br>\n",
        "2. Define a number of operations to perform on this data set using your `Pipeline` object.<br>\n",
        "3. Execute these operations by calling the `Pipeline’s` `sample()` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Egt9EHjR-Dd"
      },
      "source": [
        "path_to_training_dataset=\"/content/gdrive/MyDrive/cnn-upgrad/Train/\"\n",
        "import Augmentor\n",
        "for i in class_names:\n",
        "    print(path_to_training_dataset + i)\n",
        "    p = Augmentor.Pipeline(path_to_training_dataset + i)\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.sample(500) ## We are adding 500 samples per class to make sure that none of the classes are sparse."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcBIFZGbWuFa"
      },
      "source": [
        "Augmentor has stored the augmented images in the output sub-directory of each of the sub-directories of skin cancer types.. Lets take a look at total count of augmented images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxWcMqZhdRWz"
      },
      "source": [
        "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
        "print(image_count_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ5KarKq4kWJ"
      },
      "source": [
        "### Lets see the distribution of augmented data after adding new images to the original training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZvVdF7g3E1z"
      },
      "source": [
        "path_list_new = [x for x in glob.glob(os.path.join(data_dir_train, '*', 'output','*.jpg'))]\n",
        "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob.glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okcqVFAA2nxK"
      },
      "source": [
        "dataframe_dict_new = dict(zip(path_list_new, lesion_list_new))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njzBxTNT2nxK"
      },
      "source": [
        "df2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])\n",
        "new_df = original_df.append(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j45rmxd2nxK"
      },
      "source": [
        "df2['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NirFBvGPmgI"
      },
      "source": [
        "So, now we have added 500 images to all the classes to maintain some class balance. We can add more images as we want to improve training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EnspeMbRWNs"
      },
      "source": [
        "#### **Todo**: Train the model on the data created using Augmentor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFcj1XgndRWz"
      },
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in path_list:\n",
        "  os.remove(file)\n"
      ],
      "metadata": {
        "id": "PF4aUQl0J-9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move output files to main class folder\n",
        "for new_path in path_list_new:\n",
        "  shutil.move(new_path,os.path.dirname(os.path.dirname(new_path))+'/'+os.path.basename(new_path))\n"
      ],
      "metadata": {
        "id": "QDCO8wRXMxn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for class_name in class_names:\n",
        "  os.chdir('/content/gdrive/MyDrive/cnn-upgrad/Train/'+class_name)\n",
        "  os.removedirs('output')"
      ],
      "metadata": {
        "id": "hv-B3TWDRWYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0haOU11Ey8ey"
      },
      "source": [
        "####  Create a training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4ZY11judRWz"
      },
      "source": [
        "data_dir_train=\"/content/gdrive/MyDrive/cnn-upgrad/Train\"\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'training',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwNJVDuBP5kf"
      },
      "source": [
        "####  Create a validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX191d_3dRW0"
      },
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'validation',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaoWeOEpVjqH"
      },
      "source": [
        "#### Creating Model 3 using Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation\n",
        "\n",
        "Data Augmentation is primarily used for two reasons — to improve the variability of the dataset and also to increase the size of the dataset. This helps increase the robustness of the Deep Learning algorithm that is trained from this data."
      ],
      "metadata": {
        "id": "S-jUkhDAeFuE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch0MuKvFVr7O"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(len(class_names)))\n",
        "model.add(Activation('softmax'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu5N9LxkVx1B"
      },
      "source": [
        "#### Compile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H47GWmLbdRW1"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gS-Y1bJV7uy"
      },
      "source": [
        "#### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcV6OdI4dRW1"
      },
      "source": [
        "epochs = 50\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuvfCTsBWLMp"
      },
      "source": [
        "#### Visualize the model results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCTXwfkTdRW1"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "_kNzoyggl_2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Way4lakC4_p0"
      },
      "source": [
        "## Final Model's Observations\n",
        "\n",
        "\n",
        "The training accuracy seems to be nearly ~90%. The validation accuracy is nearly ~80%. Though the model accuracy has improved, the class rebalance has helped treat the overfitting to some extent.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Did you get rid of underfitting/overfitting? Did class rebalance help?\n",
        "YES, the class rebalance has helped treat the overfitting to some extent."
      ],
      "metadata": {
        "id": "xSUp82-hmzxG"
      }
    }
  ]
}